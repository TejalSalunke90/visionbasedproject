{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fb13646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "import csv\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from scipy.stats import randint\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07a7d189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy import stats\n",
    "#from my_ml_lib import DataManipulationTools, MetricTools, PlotTools\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "812ecafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import different classifiers\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage.feature import hog, local_binary_pattern, greycomatrix, greycoprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b5f0009",
   "metadata": {},
   "outputs": [],
   "source": [
    "path= r\"C:\\Users\\tejal\\Desktop\\Tejal Salunke\\college\\CV\\CV project\\dataset\\train\"\n",
    "def read_images(path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    num1 = 32\n",
    "    num2 = 32\n",
    "    for file_name in os.listdir(path):\n",
    "        file_path = path + '/' + file_name\n",
    "        for img_name in os.listdir(file_path):\n",
    "            if not img_name.startswith('.'):\n",
    "                if img_name.endswith('.png'):\n",
    "                    img = cv2.imread(file_path + '/' + img_name)\n",
    "                    new_img = cv2.resize(img, (num2, num1))\n",
    "                    images.append(new_img)\n",
    "                    if file_name == 'Parasitized':\n",
    "                        label = 0\n",
    "                    else:\n",
    "                        label = 1\n",
    "                    labels.append(label)\n",
    "    \n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8bc0b9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_feature(feature, name):\n",
    "    # saving all our feature vectors in pickled file\n",
    "    with open('cache/' + name + '.pkl', 'wb') as fp:\n",
    "        pickle.dump(csr_matrix(feature), fp)\n",
    "    \n",
    "    print(f'Feature saved with name cache/{name}.pkl')\n",
    "\n",
    "def load_feature(feature_name):\n",
    "    return pickle.load(open(feature_name, 'rb')).A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "386b2c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model):\n",
    "    filename = input('Enter model file name:')\n",
    "    pickle.dump(model, open('models/'+filename + '.pkl', 'wb'))\n",
    "    print(f'Successfully saved model in models/{filename}.pkl')\n",
    "\n",
    "def load_model(model_name):\n",
    "    return pickle.load(open(model_name, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fdfc0b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gabor(images, name=\"gabor\", save=False):\n",
    "    \n",
    "    # Gabor filter banks with different orientations and at different scales\n",
    "    filters = []\n",
    "    ksize = 9\n",
    "    sigma = 0.1\n",
    "    gamma = 0.5\n",
    "    phi = 0\n",
    "    \n",
    "    # define the range for theta and nu\n",
    "    for theta in np.arange(0, np.pi, np.pi / 8):\n",
    "        for nu in np.arange(0, 6*np.pi/4, np.pi / 4):\n",
    "            kern = cv2.getGaborKernel((ksize, ksize), sigma, theta, nu, gamma, phi, ktype=cv2.CV_32F)\n",
    "            kern /= 1.5*kern.sum()\n",
    "            filters.append(kern)\n",
    "    \n",
    "    # function to convolve the image with the filters\n",
    "    def process(img, filters):\n",
    "        accum = np.zeros_like(img)\n",
    "        for kern in filters:\n",
    "            fimg = cv2.filter2D(img, cv2.CV_8UC3, kern)\n",
    "            np.maximum(accum, fimg, accum)\n",
    "            return accum\n",
    "        \n",
    "    \n",
    "    def get_image_gabor(image):\n",
    "        # Local Binary Pattern\n",
    "        f = []\n",
    "\n",
    "        # calculating the local energy for each convolved image\n",
    "        for j in range(40):\n",
    "            res = process(cv2.cvtColor(image, cv2.COLOR_RGB2GRAY), filters[j])\n",
    "            res = np.array(res)\n",
    "            f.append(np.sum(np.multiply(res, res)))\n",
    "\n",
    "        # calculating the mean amplitude for each convolved image\n",
    "        for j in range(40):\n",
    "            res = process(cv2.cvtColor(image, cv2.COLOR_RGB2GRAY), filters[j])\n",
    "            res = np.array(res)\n",
    "            f.append(np.sum(abs(res)))\n",
    "        return f\n",
    "    \n",
    "    # Gabor descriptor for all images\n",
    "    features = []\n",
    "    for i, img in enumerate(images):\n",
    "        f = get_image_gabor(img)\n",
    "        features.append(f)\n",
    "    \n",
    "    result = np.array(features)\n",
    "    \n",
    "    if save:\n",
    "        save_feature(result, name)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e7c4e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_x, train_y, model_name='NB', validation=None):\n",
    "    \"\"\"\n",
    "    Possible model names: ['NB', 'SVM', 'XGB', 'MLP', 'ADA', 'BAG', 'RF']\n",
    "    default = 'NB'\n",
    "    \n",
    "    validation: (val_x, val_y) tupple for validation accuracy score.\n",
    "    \n",
    "    return: trained model\n",
    "    \"\"\"\n",
    "    model = None\n",
    "    if model_name == 'SVM':\n",
    "        model = svm.SVC(gamma='scale', probability=True)\n",
    "    elif model_name == 'XGB':\n",
    "        model = XGBClassifier(n_estimators=200, max_depth=5, n_jobs=2)\n",
    "#         model = XGBClassifier()\n",
    "    elif model_name == 'MLP':\n",
    "        model = MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=800, alpha=0.0001,\n",
    "                     solver='sgd', verbose=10, tol=0.000000001)\n",
    "    elif model_name == 'ADA':\n",
    "        model = AdaBoostClassifier(n_estimators=50)\n",
    "    elif model_name == 'BAG':\n",
    "        model = BaggingClassifier(n_jobs=2, n_estimators=50)\n",
    "    elif model_name == 'RF':\n",
    "        model = RandomForestClassifier(n_estimators=200, max_depth=10)\n",
    "    elif model_name == 'KNN':\n",
    "        model = KNeighborsClassifier(n_neighbors=5, weights='distance', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
    "    else:\n",
    "        model = GaussianNB()\n",
    "    \n",
    "    model.fit(train_x, train_y)\n",
    "    \n",
    "    if validation is not None:\n",
    "        y_hat = model.predict(validation[0])\n",
    "        acc = metrics.accuracy_score(validation[1], y_hat)\n",
    "        print(f\"Validation Accuracy in '{model_name}' = {acc}\")\n",
    "        cm = metrics.confusion_matrix(validation[1], y_hat)\n",
    "        print(cm)\n",
    "        recall = cm[0][0] / (cm[0][0] + cm[0][1])\n",
    "        precision = cm[0][0] / (cm[0][0] + cm[1][0])\n",
    "        f1 = 2*(precision*recall)/(precision+recall)\n",
    "        print(f\"Recall in '{model_name}' = {recall}\")\n",
    "        print(f\"Precision in '{model_name}' = {precision}\")\n",
    "        print(f\"F1 Score in '{model_name}' = {f1}\")\n",
    "               \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5ed182b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1= r\"C:\\Users\\tejal\\Desktop\\Tejal Salunke\\college\\CV\\CV project\\dataset\\train\"\n",
    "full_data_x, full_data_y = read_images(input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7458305a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size :  (0,) (0,)\n"
     ]
    }
   ],
   "source": [
    "print(\"dataset size : \", full_data_x.shape, full_data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f6dc59e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14092/1624873972.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"One Image size: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_data_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "print(\"One Image size: \", full_data_x[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c329c957",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.75 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14092/2852797336.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_data_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_data_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.75\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2174\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2175\u001b[1;33m     n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size,\n\u001b[0m\u001b[0;32m   2176\u001b[0m                                               default_test_size=0.25)\n\u001b[0;32m   2177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1856\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1857\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   1858\u001b[0m             \u001b[1;34m'With n_samples={}, test_size={} and train_size={}, the '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1859\u001b[0m             \u001b[1;34m'resulting train set will be empty. Adjust any of the '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.75 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "data_x, test_x, data_y, test_y = train_test_split(full_data_x, full_data_y, test_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2c54f47c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14092/3890087844.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr\"C:\\Users\\tejal\\Desktop\\Tejal Salunke\\college\\CV\\CV project\\dataset\\train\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "input=r\"C:\\Users\\tejal\\Desktop\\Tejal Salunke\\college\\CV\\CV project\\dataset\\train\"\n",
    "input.shape()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a835fbab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
